{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from Bio import AlignIO\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "from Bio.Blast import NCBIWWW, NCBIXML\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "from sup_data_to_fasta import load_xlsx, transform_raw_dfs_to_queries\n",
    "\n",
    "sup5_file_path = Path(\"../data/Liu_sup5_data.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória dos Dados Suplementares 5\n",
    "\n",
    "## Sobre\n",
    "\n",
    "Este notebook contém uma análise exploratória dos dados fornecidos por Liu, et al. No [suplemento 5](https://www.nature.com/articles/s41467-023-43632-1#additional-information\n",
    ") com o objetivo de averiguar os tratamentos executados no artigo\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "* Verificar a origem das tags dos pares sRNA/mRNA dos dados suplementares.\n",
    "* Ganhar mais insight sobre as interações medidas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def load_alignments():\n",
    "    output_dir = Path(\"/workspaces/sRNAs_Interactomes/output\")\n",
    "    alignments_files = output_dir.glob(\"*alignments_results.tsv\")\n",
    "    \n",
    "    exp_word_size_list = []\n",
    "\n",
    "    alignments_df_list = []\n",
    "    for file_path in alignments_files:\n",
    "        prefix = file_path.stem.split(\"_\")[0]\n",
    "        df = pd.read_csv(file_path, sep='\\t')\n",
    "        word_sz = prefix.split(\"w\")[1]\n",
    "        experiment = prefix.split(\"-\")[0]\n",
    "        exp_word_size_list.append((experiment, word_sz))\n",
    "        df[\"experiment\"] = experiment\n",
    "        df[\"word_sz\"] = word_sz\n",
    "        alignments_df_list.append(df)\n",
    "    \n",
    "    alignments_dict = {(exp, word_sz): df for (exp, word_sz), df in zip(exp_word_size_list, alignments_df_list)}\n",
    "    return alignments_dict, exp_word_size_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alignments_dict, exp_word_size_list = load_alignments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries():\n",
    "    sup5_file_path = Path(\"/workspaces/sRNAs_Interactomes/data/Liu_sup5_data.xlsx\")\n",
    "    dict = load_xlsx(sup5_file_path)\n",
    "    queries_dict = transform_raw_dfs_to_queries(dict)\n",
    "    queries_dict = {k.split('-')[0]:v for k,v in queries_dict.items()}\n",
    "    return queries_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_dict = load_queries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('EP', '11')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m queries_df \u001b[38;5;241m=\u001b[39m queries_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEP\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m alignments_df \u001b[38;5;241m=\u001b[39m \u001b[43malignments_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m11\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#queries \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(queries_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#alignments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(alignments_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: ('EP', '11')"
     ]
    }
   ],
   "source": [
    "queries_df = queries_dict['EP']\n",
    "alignments_df = alignments_dict[('EP', '11')]\n",
    "print(f\"#queries {len(queries_df)}\")\n",
    "print(f\"#alignments {len(alignments_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_dfs(queries_df, alignments_df):\n",
    "    joined_df = pd.merge(queries_df, alignments_df, left_on='name', right_on='qseqid', how='left', suffixes=('_query', '_alignment'))\n",
    "    return joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_queries_dict = {}\n",
    "for (exp, word_sz) in exp_word_size_list:\n",
    "    queries_df = queries_dict[exp]\n",
    "    alignments_df = alignments_dict[(exp, word_sz)]\n",
    "    joined_df = join_dfs(queries_df, alignments_df)\n",
    "    aligned_queries_dict[(exp, word_sz)] = joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_aligned_dict = {}\n",
    "\n",
    "for (exp, word_sz), df in sorted(aligned_queries_dict.items()):\n",
    "    non_aligned_queries = df[df['qseqid'].isnull()]\n",
    "    \n",
    "    print(f\"Number of queries in {exp} experiment not aligned for word_size={word_sz}: {len(non_aligned_queries)}\")\n",
    "    if len(non_aligned_queries):\n",
    "        not_aligned_dict[(exp, word_sz)] = non_aligned_queries['name'].tolist()\n",
    "        # print(f\"Queries not aligned in {exp} experiment for word_size={word_sz}: {non_aligned_queries['name'].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Queries not aligned in EP experiment for word_size=15: ['SL1344_1792(SL1344_1792).SL1344_1791(SL1344_1791).IGR', 'SL1344_1967(SL1344_1967)', 'SL1344_2696(SL1344_2696)', 'SL1344_2698(SL1344_2698)', 'STnc1680(ncRNA0265)', 'gpB(SL1344_2645).AS', 'rfbX(SL1344_2065)']\n",
      "Queries not aligned in ESP experiment for word_size=15: ['SL1344_1967(SL1344_1967)', 'SL1344_1968(SL1344_1968)', 'SL1344_1976(SL1344_1976).AS', 'SL1344_2696(SL1344_2696)', 'SL1344_2698(SL1344_2698)', 'cspE(SL1344_0617)', 'folA(SL1344_0088)', 'gpB(SL1344_2645)', 'gpB(SL1344_2645).AS']\n",
      "Queries not aligned in SP experiment for word_size=10: ['ibsC(SL1344_3172A ).SL1344_3172(SL1344_3172).IGR']\n",
      "Queries not aligned in SP experiment for word_size=11: ['ibsC(SL1344_3172A ).SL1344_3172(SL1344_3172).IGR', 'sopE(SL1344_2674)']\n",
      "Queries not aligned in SP experiment for word_size=15: ['SL1344_1967(SL1344_1967)', 'SL1344_2593(SL1344_2593)', 'SL1344_2696(SL1344_2696)', 'SL1344_2698(SL1344_2698)', 'SL1344_2715(SL1344_2715)', 'STnc1680(ncRNA0265)', 'cspE(SL1344_0617)', 'folA(SL1344_0088)', 'gpB(SL1344_2645)', 'gpB(SL1344_2645).AS', 'ibsC(SL1344_3172A ).SL1344_3172(SL1344_3172).IGR', 'sopE(SL1344_2674)']\n",
      "Queries not aligned in SP experiment for word_size=4: ['ibsC(SL1344_3172A ).SL1344_3172(SL1344_3172).IGR']\n",
      "Queries not aligned in SP experiment for word_size=7: ['ibsC(SL1344_3172A ).SL1344_3172(SL1344_3172).IGR']\n",
      "Queries not aligned in SP experiment for word_size=8: ['ibsC(SL1344_3172A ).SL1344_3172(SL1344_3172).IGR']\n",
      "Queries not aligned in SP experiment for word_size=9: ['ibsC(SL1344_3172A ).SL1344_3172(SL1344_3172).IGR']\n"
     ]
    }
   ],
   "source": [
    "for (exp, word_sz), not_aligned in sorted(not_aligned_dict.items()):\n",
    "    print(f\"Queries not aligned in {exp} experiment for word_size={word_sz}: {not_aligned}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
